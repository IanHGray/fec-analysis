{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from neo4j import GraphDatabase\n",
    "from tqdm.notebook import tqdm\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.config(\n",
    "        \"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\"\n",
    "    )\n",
    "    .config(\"spark.sql.hive.convertMetastoreParquet\", \"false\")\n",
    "    .config(\"spark.driver.memory\", \"10g\")\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"10\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to write data to connection ResolvedIPv4Address(('34.121.155.65', 7687)) (ResolvedIPv4Address(('34.121.155.65', 7687)))\n"
     ]
    }
   ],
   "source": [
    "class Neo4jConnection:\n",
    "    def __init__(self):\n",
    "        self.uri = None\n",
    "        self.username = 'neo4j'\n",
    "        self.password = None\n",
    "\n",
    "    def connect_to_graph(self):\n",
    "        try:\n",
    "            if self.password is None:\n",
    "                self.driver = GraphDatabase.driver(self.uri)\n",
    "            else:\n",
    "                self.driver = GraphDatabase.driver(\n",
    "                    self.uri, auth=(self.username, self.password), max_connection_lifetime=200\n",
    "                )\n",
    "            print(\"Connected to Neo4j\")\n",
    "        except Exception as e:\n",
    "            print(\"Failed to establish connection\", e)\n",
    "    def close(self):\n",
    "        if self.driver is not None:\n",
    "            self.driver.close()\n",
    "\n",
    "    def query(self, query, parameters=None, db=None):\n",
    "        assert self.driver is not None, \"Driver not initialized!\"\n",
    "        session = None\n",
    "        response = None\n",
    "        try:\n",
    "            session = (\n",
    "                self.driver.session(database=db)\n",
    "                if db is not None\n",
    "                else self.driver.session()\n",
    "            )\n",
    "            response = list(session.run(query, parameters))\n",
    "        except Exception as e:\n",
    "            if \"equivalent constraint already exists\" in str(e):\n",
    "                print(\"Uniqueness constraint already exists\")\n",
    "            else:\n",
    "                print(\"Query failed:\", e)\n",
    "        finally:\n",
    "            if session is not None:\n",
    "                session.close()\n",
    "        return response\n",
    "\n",
    "class FECParser:\n",
    "    def __init__(self):\n",
    "        self.conn = None\n",
    "        self.expenditure_data = 'raw_data/oppexp.txt'\n",
    "        self.minimum_transaction = 5000\n",
    "        self.candidate_list = 'raw_data/cn.txt'\n",
    "        self.committee_list = 'raw_data/cm.txt'\n",
    "        self.committee_contributions_filepath = 'raw_data/itpas2.txt'\n",
    "        self.candidate_committee_linkages_filepath = 'raw_data/ccl.txt'\n",
    "        self.committee_transactions_filepath = 'raw_data/itoth.txt'\n",
    "        self.committees = []\n",
    "        self.entities = []\n",
    "        self.DISBURSES_TO = []\n",
    "        self.candidates = []\n",
    "\n",
    "    def load_expenditures(self): \n",
    "        self.operating_expenditures = pd.read_csv(self.bulk_data, sep='|', header=None)\n",
    "        #For the sake of simplicity, I am manually labeling these columns here. Each bulk file is accompanied by a header file, from which these columns were derived.\n",
    "        self.operating_expenditures.columns=['CMTE_ID',\n",
    "         'AMNDT_IND',\n",
    "         'RPT_YR',\n",
    "         'RPT_TP',\n",
    "         'IMAGE_NUM',\n",
    "         'LINE_NUM',\n",
    "         'FORM_TP_CD',\n",
    "         'SCHED_TP_CD',\n",
    "         'NAME',\n",
    "         'CITY',\n",
    "         'STATE',\n",
    "         'ZIP_CODE',\n",
    "         'TRANSACTION_DT',\n",
    "         'TRANSACTION_AMT',\n",
    "         'TRANSACTION_PGI',\n",
    "         'PURPOSE',\n",
    "         'CATEGORY',\n",
    "         'CATEGORY_DESC',\n",
    "         'MEMO_CD',\n",
    "         'MEMO_TEXT',\n",
    "         'ENTITY_TP',\n",
    "         'SUB_ID',\n",
    "         'FILE_NUM',\n",
    "         'TRAN_ID',\n",
    "         'BACK_REF_TRAN_ID',\n",
    "         'placeholder']\n",
    "        return self\n",
    "    \n",
    "    def filter_by_transaction_size(self):\n",
    "        self.operating_expenditures = self.operating_expenditures.loc[self.operating_expenditures['TRANSACTION_AMT'] >= self.minimum_expenditure]\n",
    "        return self\n",
    "\n",
    "    def load_candidates(self):\n",
    "        self.candidate_data =  pd.read_csv('raw_data/cn.txt', sep='|', header=None)\n",
    "        self.candidate_data.columns = ['CAND_ID',\n",
    "        'CAND_NAME',\n",
    "        'CAND_PTY_AFFILIATION',\n",
    "        'CAND_ELECTION_YR',\n",
    "        'CAND_OFFICE_ST',\n",
    "        'CAND_OFFICE',\n",
    "        'CAND_OFFICE_DISTRICT',\n",
    "        'CAND_ICI',\n",
    "        'CAND_STATUS',\n",
    "        'CAND_PCC',\n",
    "        'CAND_ST1',\n",
    "        'CAND_ST2',\n",
    "        'CAND_CITY',\n",
    "        'CAND_ST',\n",
    "        'CAND_ZIP']\n",
    "        return self\n",
    "    \n",
    "    def write_candidates(self):\n",
    "        with self.conn.driver.session() as session:\n",
    "            tx  = session.begin_transaction()\n",
    "            commit_limit = 0\n",
    "            for index, rows in tqdm(self.candidate_data.iterrows(), total = len(self.candidate_data), desc = 'Inserting candidates'):\n",
    "                candidate_id = '\"' + str(rows['CAND_ID']) + '\"'\n",
    "                candidate_name = '\"' + str(rows['CAND_NAME']).replace('\"', '') + '\"'\n",
    "                candidate_party = '\"' + str(rows['CAND_PTY_AFFILIATION']).replace('\"', '') + '\"'\n",
    "                candidate_office_state = '\"' + str(rows['CAND_OFFICE_ST']).replace('\"', '') + '\"'\n",
    "                candidate_district = '\"' + str(str(rows['CAND_OFFICE_DISTRICT'])).replace('\"', '') + '\"'\n",
    "                candidate_office = str(rows['CAND_OFFICE']).replace('\"', '').replace('H', 'house').replace('P', 'president').replace('S', 'senate') #Expand these labels to be more easily read\n",
    "                candidate_ici = '\"' + str(rows['CAND_ICI']).replace('\"', '') + '\"'\n",
    "                candidate_status = '\"' + str(rows['CAND_STATUS']).replace('\"', '') + '\"'\n",
    "                \n",
    "                \n",
    "                cypher_statement = f\"\"\"MERGE (can:candidate:{candidate_office} {{candidate_id: {candidate_id}}})\n",
    "                                    ON CREATE SET can.candidate_name = {candidate_name},\n",
    "                                    can.candidate_party = {candidate_party},\n",
    "                                    can.candidate_office_state = {candidate_office_state},\n",
    "                                    can.candidate_district = {candidate_district},\n",
    "                                    can.candidate_office = {'\"' + candidate_office + '\"'},\n",
    "                                    can.candidate_ici = {candidate_ici},\n",
    "                                    can.candidate_status = {candidate_status}\n",
    "                                    \"\"\"\n",
    "                tx.run(cypher_statement)\n",
    "                commit_limit +=1\n",
    "                if commit_limit == 100:\n",
    "                    tx.commit()\n",
    "                    commit_limit = 0\n",
    "                    tx = session.begin_transaction()\n",
    "        session.close()\n",
    "        return self\n",
    "\n",
    "    def load_committees(self):\n",
    "        self.committees_data = pd.read_csv(self.committee_list, sep='|', header=None)\n",
    "        self.committees_data.columns = [\n",
    "        'CMTE_ID',\t\n",
    "        'CMTE_NM',\t\n",
    "        'TRES_NM',\t\n",
    "        'CMTE_ST1',\t\n",
    "        'CMTE_ST2',\t\n",
    "        'CMTE_CITY',\t\n",
    "        'CMTE_ST',\t\n",
    "        'CMTE_ZIP',\t\n",
    "        'CMTE_DSGN',\t\n",
    "        'CMTE_TP',\t\n",
    "        'CMTE_PTY_AFFILIATION',\t\n",
    "        'CMTE_FILING_FREQ',\t\n",
    "        'ORG_TP',\t\n",
    "        'CONNECTED_ORG_NM',\t\n",
    "        'CAND_ID'\n",
    "        ]\n",
    "        self.committees_data.fillna('Not Included in Data', inplace=True)\n",
    "        return self\n",
    "\n",
    "    def write_committees(self):\n",
    "        with self.conn.driver.session() as session:\n",
    "            tx  = session.begin_transaction()\n",
    "            commit_limit = 0\n",
    "            for index, rows in tqdm(self.committees_data.iterrows(), total = len(self.committees_data), desc='Writing Committees'):\n",
    "                committee_id = '\"' + str(rows['CMTE_ID']) + '\"'\n",
    "                committee_name = '\"' + str(rows['CMTE_NM']).replace('\"', '') + '\"'\n",
    "                committee_party = '\"' + str(rows['CMTE_PTY_AFFILIATION']) + '\"'\n",
    "                committee_type = '\"' + str(rows['ORG_TP']) + '\"'\n",
    "                committee_designation = '\"' + str(rows['CMTE_DSGN']).replace('\"', '') + '\"'\n",
    "                cypher_statement = f\"\"\"MERGE (c:committee {{committee_id: {committee_id}}})\n",
    "                                ON CREATE SET c.committee_name = {committee_name},\n",
    "                                c.committee_party = {committee_party},\n",
    "                                c.committee_type = {committee_type},\n",
    "                                c.committee_designation = {committee_designation}\n",
    "                                \"\"\"\n",
    "                tx.run(cypher_statement)\n",
    "                commit_limit +=1\n",
    "                if commit_limit == 100:\n",
    "                    tx.commit()\n",
    "                    commit_limit = 0\n",
    "                    tx = session.begin_transaction()\n",
    "        session.close()\n",
    "        return self\n",
    "\n",
    "    def write_affiliated_organizations(self):\n",
    "        with self.conn.driver.session() as session:\n",
    "            tx  = session.begin_transaction()\n",
    "            commit_limit = 0\n",
    "            for index, rows in tqdm(self.committees_data.iterrows(), total=len(self.committees_data), desc='Writing affiliated organizations'):\n",
    "                connected_organization = str(rows['CONNECTED_ORG_NM'])\n",
    "                if connected_organization != 'Not Included in Data' and connected_organization != \"NONE\":\n",
    "                    cypher_statement = f\"\"\"MERGE (o:organization {{organization_name: {'\"' + connected_organization.replace('\"', '') + '\"'}}})\"\"\"\n",
    "                    tx.run(cypher_statement)\n",
    "                        \n",
    "                    commit_limit +=1\n",
    "                    if commit_limit == 100:\n",
    "                        tx.commit()\n",
    "                        commit_limit = 0\n",
    "                        tx = session.begin_transaction()\n",
    "            session.close()\n",
    "            return self \n",
    "\n",
    "    def write_AFFILIATED_WITH(self):\n",
    "        with self.conn.driver.session() as session:\n",
    "            tx  = session.begin_transaction()\n",
    "            commit_limit = 0\n",
    "            for index, rows in tqdm(self.committees_data.iterrows(), total = len(self.committees_data), desc = 'Writing committee affiliaitons'):\n",
    "                committee_id = '\"' + str(rows['CMTE_ID']) + '\"'\n",
    "                connected_organization = str(rows['CONNECTED_ORG_NM'])\n",
    "                if connected_organization != 'Not Included in Data' and connected_organization != \"NONE\":\n",
    "                    cypher_statement = f\"\"\"MATCH (c:committee {{committee_id: {committee_id}}})\n",
    "                                            MATCH (o:organization {{organization_name: {'\"' + connected_organization.replace('\"', '') + '\"'}}})\n",
    "                                            MERGE (c)-[:AFFILIATED_WITH]->(o)\"\"\"\n",
    "                    tx.run(cypher_statement)\n",
    "                        \n",
    "                    commit_limit +=1\n",
    "                    if commit_limit == 100:\n",
    "                        tx.commit()\n",
    "                        commit_limit = 0\n",
    "                        tx = session.begin_transaction()\n",
    "            session.close()\n",
    "            return self \n",
    "\n",
    "    def write_PRINCIPAL_COMMITTEE_OF(self):\n",
    "        with self.conn.driver.session() as session:\n",
    "            tx  = session.begin_transaction()\n",
    "            commit_limit = 0\n",
    "            for index, rows in tqdm(self.candidate_data.iterrows(), total=len(self.candidate_data), desc='Inserting primary committee relationships'):\n",
    "                candidate_id = '\"' + rows['CAND_ID'] + '\"'\n",
    "                candidate_pcc = '\"' + str(rows['CAND_PCC']).replace('\"', '') + '\"'\n",
    "                cypher_statement = f\"\"\"MATCH (can:candidate {{candidate_id: {candidate_id}}})\n",
    "                                    MATCH (c:committee {{committee_id: {candidate_pcc}}})\n",
    "                                    MERGE (c)-[:PRINCIPAL_COMMITTEE_OF]->(can)\"\"\"        \n",
    "                tx.run(cypher_statement)\n",
    "                commit_limit +=1\n",
    "                if commit_limit == 100:\n",
    "                    tx.commit()\n",
    "                    commit_limit = 0\n",
    "                    tx = session.begin_transaction()\n",
    "        session.close()\n",
    "        return self\n",
    "\n",
    "    def parse_expenditures(self):\n",
    "        for index, rows in tqdm(self.operating_expenditures.iterrows(), total = len(self.operating_expenditures), desc='parsing data'):\n",
    "            committee_id = rows['CMTE_ID']\n",
    "            self.committees.append(committee_id)\n",
    "            entity_name = rows['NAME']\n",
    "            entity_type = rows['ENTITY_TP']\n",
    "            entity_row = {}\n",
    "            entity_row['entity_name'] = entity_name\n",
    "            entity_row['entity_type'] = entity_type\n",
    "            self.entities.append(entity_row)\n",
    "            DISBURSES_TO_row = {}\n",
    "            DISBURSES_TO_row['committee_id'] = committee_id\n",
    "            DISBURSES_TO_row['entity_name'] = entity_name\n",
    "            DISBURSES_TO_row['amount'] = rows['TRANSACTION_AMT']\n",
    "            DISBURSES_TO_row['purpose'] = rows['PURPOSE']\n",
    "            DISBURSES_TO_row['category'] = rows['CATEGORY']\n",
    "            DISBURSES_TO_row['date'] = rows['TRANSACTION_DT']\n",
    "            DISBURSES_TO_row['transaction_id'] = rows['TRAN_ID']\n",
    "            self.DISBURSES_TO.append(DISBURSES_TO_row)\n",
    "        return self\n",
    "    \n",
    "    def write_entities(self):\n",
    "        with self.conn.driver.session() as session:\n",
    "                tx  = session.begin_transaction()\n",
    "                commit_limit = 0\n",
    "                for item in tqdm(self.entities, total = len(self.entities), desc='Inserting entities'):\n",
    "                    try:\n",
    "                        entity_name = '\"' + str(item['entity_name']).replace('\"', '').lower() + '\"'\n",
    "                        entity_type = str(item['entity_type']).replace('\"', '').lower()\n",
    "                        cypher_statement = f\"\"\"MERGE (e:entity:{entity_type} {{entity_name: {entity_name}}})\n",
    "                        ON CREATE SET e.entity_type = {'\"' + entity_type + '\"'}\"\"\"                        \n",
    "                        tx.run(cypher_statement)\n",
    "                        commit_limit +=1\n",
    "                        if commit_limit == 100:\n",
    "                            tx.commit()\n",
    "                            commit_limit = 0\n",
    "                            tx = session.begin_transaction()\n",
    "                    except Exception as e:\n",
    "                        print(str(e))\n",
    "        session.close()\n",
    "        return self  \n",
    "\n",
    "    def write_DISBURSES_TO(self):\n",
    "        with self.conn.driver.session() as session:\n",
    "                tx  = session.begin_transaction()\n",
    "                commit_limit = 0\n",
    "                for item in tqdm(self.DISBURSES_TO, total = len(self.DISBURSES_TO), desc='Inserting entities'):\n",
    "                    try:\n",
    "                        entity_name = '\"' + str(item['entity_name']).replace('\"', '').lower() + '\"'\n",
    "                        committee_id = '\"' + str(item['committee_id']) + '\"'\n",
    "                        purpose = '\"' + str(item['purpose']).replace('\"', '') + '\"'\n",
    "                        category = '\"' + str(item['category']).replace('\"', '') + '\"'\n",
    "                        date = '\"' + str(item['date']) + '\"'\n",
    "                        transaction_id = '\"' + str(item['transaction_id']) + '\"'\n",
    "                        amount = item['amount']\n",
    "\n",
    "                        cypher_statement = f\"\"\"MATCH (e:entity {{entity_name: {entity_name}}})\n",
    "                                            MATCH (c:committee {{committee_id: {committee_id}}})\n",
    "                                            MERGE (c)-[d:DISBURSES_TO]->(e)\n",
    "                                            SET d.amount = {amount},\n",
    "                                            d.purpose = {purpose},\n",
    "                                            d.category = {category},\n",
    "                                            d.date = {date},\n",
    "                                            d.transaction_id = {transaction_id}\n",
    "                                            \"\"\"\n",
    "                        tx.run(cypher_statement)\n",
    "                        commit_limit +=1\n",
    "                        if commit_limit == 100:\n",
    "                            tx.commit()\n",
    "                            commit_limit = 0\n",
    "                            tx = session.begin_transaction()\n",
    "                    except Exception as e:\n",
    "                        print(str(e))\n",
    "        session.close()\n",
    "        return self\n",
    "\n",
    "    def load_committee_contributions(self):\n",
    "        self.committee_contributions = pd.read_csv(self.committee_contributions_filepath, sep='|', header=None)\n",
    "        self.committee_contributions.columns = [\n",
    "        'CMTE_ID',\n",
    "        'AMNDT_IND',\n",
    "        'RPT_TP',\n",
    "        'TRANSACTION_PGI',\n",
    "        'IMAGE_NUM',\n",
    "        'TRANSACTION_TP',\n",
    "        'ENTITY_TP',\n",
    "        'NAME',\n",
    "        'CITY',\n",
    "        'STATE',\n",
    "        'ZIP_CODE',\n",
    "        'EMPLOYER',\n",
    "        'OCCUPATION',\n",
    "        'TRANSACTION_DT',\n",
    "        'TRANSACTION_AMT',\n",
    "        'OTHER_ID',\n",
    "        'CAND_ID',\n",
    "        'TRAN_ID',\n",
    "        'FILE_NUM',\n",
    "        'MEMO_CD',\n",
    "        'MEMO_TEXT',\n",
    "        'SUB_ID']\n",
    "        return self\n",
    "\n",
    "    def handle_timeout(default_response):\n",
    "        def decorator(func):\n",
    "            \n",
    "    def write_COMMITTEE_CONTRIBUTES_TO(self, starting_point=0):\n",
    "        with self.conn.driver.session() as session:\n",
    "                tx  = session.begin_transaction()\n",
    "                commit_limit = 0\n",
    "                insert_data = self.committee_contributions[starting_point:]\n",
    "                for index, rows in tqdm(self.insert_data.iterrows(), total = len(self.committee_contributions), desc='Inserting committee contributions'):\n",
    "                    source_committee_id = '\"' + str(rows['CMTE_ID']) + '\"'\n",
    "                    date = '\"' + str(rows['TRANSACTION_DT']) + '\"'\n",
    "                    amount = rows['TRANSACTION_AMT']\n",
    "                    candidate_id = '\"' + str(rows['CAND_ID']) + '\"'\n",
    "                    target_committee_id = '\"' + str(rows['OTHER_ID']) + '\"'\n",
    "                    transaction_id = '\"' + str(rows['TRAN_ID']) + '\"'\n",
    "                    transaction_type = '\"' + str(rows['TRANSACTION_TP']) + '\"'\n",
    "\n",
    "                    cypher_statement = f\"\"\"MATCH (c1:committee {{committee_id: {source_committee_id}}})\n",
    "                                MATCH (c2:committee {{committee_id: {target_committee_id}}})\n",
    "                                MERGE (c1)-[t:CONTRIBUTES_TO]->(c2)\n",
    "                                SET t.date = {date},\n",
    "                                t.transaction_id = {transaction_id},\n",
    "                                t.amount = {amount},\n",
    "                                t.transaction_type = {transaction_type}\"\"\"\n",
    "                    tx.run(cypher_statement)\n",
    "                    commit_limit +=1\n",
    "                    if commit_limit == 100:\n",
    "                        tx.commit()\n",
    "                        commit_limit = 0\n",
    "                        tx = session.begin_transaction()\n",
    "                \n",
    "        session.close()\n",
    "        return self\n",
    "\n",
    "    def write_LINKED_TO(self):\n",
    "        candidate_committee_linkages = pd.read_csv(self.candidate_committee_linkages_filepath, sep='|', header=None)\n",
    "        candidate_committee_linkages.columns = [\n",
    "        'CAND_ID',\t\n",
    "        'CAND_ELECTION_YR',\n",
    "        'FEC_ELECTION_YR',\n",
    "        'CMTE_ID',\n",
    "        'CMTE_TP',\n",
    "        'CMTE_DSGN',\n",
    "        'LINKAGE_ID']\n",
    "\n",
    "        with self.conn.driver.session() as session:\n",
    "            tx  = session.begin_transaction()\n",
    "            commit_limit = 0 \n",
    "            for index, rows in tqdm(candidate_committee_linkages.iterrows(), total = len(candidate_committee_linkages), desc='Writing candidate-committee linkages'):\n",
    "                candidate_id = '\"' + str(rows['CAND_ID']) + '\"'\n",
    "                committee_id = '\"' + str(rows['CMTE_ID']) + '\"'\n",
    "                linkage_id = '\"' + str(rows['LINKAGE_ID']) + '\"'\n",
    "                cypher_statement = f\"\"\"MATCH (can:candidate {{candidate_id: {candidate_id}}})\n",
    "                                    MATCH (c:committee {{committee_id: {committee_id}}})\n",
    "                                    MERGE (can)-[l:LINKED_TO]->(c)\n",
    "                                    SET l.linkage_id = {linkage_id}\"\"\"\n",
    "                tx.run(cypher_statement)\n",
    "                commit_limit +=1\n",
    "                if commit_limit == 100:\n",
    "                    tx.commit()\n",
    "                    commit_limit = 0\n",
    "                    tx = session.begin_transaction()\n",
    "                \n",
    "        session.close()\n",
    "        return self\n",
    "\n",
    "    def load_committee_transactions(self):\n",
    "        self.committee_transactions = pd.read_csv(self.committee_transactions_filepath, sep='|', header=None)\n",
    "        self.committee_transactions.columns = [\n",
    "        'CMTE_ID',\n",
    "        'AMNDT_IND',\n",
    "        'RPT_TP',\n",
    "        'TRANSACTION_PGI',\n",
    "        'IMAGE_NUM',\n",
    "        'TRANSACTION_TP',\n",
    "        'ENTITY_TP',\n",
    "        'NAME',\n",
    "        'CITY',\n",
    "        'STATE',\t\n",
    "        'ZIP_CODE',\t\n",
    "        'EMPLOYER',\n",
    "        'OCCUPATION',\t\n",
    "        'TRANSACTION_DT',\n",
    "        'TRANSACTION_AMT',\n",
    "        'OTHER_ID',\n",
    "        'TRAN_ID',\n",
    "        'FILE_NUM',\n",
    "        'MEMO_CD',\n",
    "        'MEMO_TEXT',\n",
    "        'SUB_ID']\n",
    "        return self\n",
    "\n",
    "    def write_transaction_entities(self):\n",
    "        \n",
    "        #There is almost certainly a more elegant way to do this than looping twice, but the goal is to eliminate duplicates that jam up Neo4j transaction time\n",
    "        entities_list = []\n",
    "        for index, rows in tqdm(self.committee_transactions.iterrows(), total = len(self.committee_transactions), desc=\"Inserting committee transactions\"):\n",
    "                entity_row = {}\n",
    "                entity_row['entity_name'] = str(rows['NAME']).replace('\"', '')\n",
    "                entity_row['entity_type'] = str(rows['ENTITY_TP'])\n",
    "                if rows['ENTITY_TP'] == 'IND':\n",
    "                    if rows['OCCUPATION'] is not None:\n",
    "                        entity_row['occupation'] = str(rows['OCCUPATION']).replace('\"', '')\n",
    "                    else:\n",
    "                        entity_row['occupation'] = 'None Listed'\n",
    "                    \n",
    "                    if rows['EMPLOYER'] is not None:\n",
    "                        entity_row['employer'] = str(rows['EMPLOYER']).replace('\"', '')\n",
    "                    else:\n",
    "                        entity_row['employer'] = 'None Listed'\n",
    "                else:\n",
    "                    entity_row['occupation'] = 'N/A'\n",
    "                    entity_row['employer'] = 'N/A'\n",
    "                \n",
    "                entities_list.append(entity_row)\n",
    "\n",
    "        entities_df = pd.DataFrame(entities_list)\n",
    "        entities_df.drop_duplicates(inplace=True)\n",
    "\n",
    "        with self.conn.driver.session() as session:\n",
    "            tx  = session.begin_transaction()\n",
    "            commit_limit = 0\n",
    "            for index, rows in entities_df.iterrows():\n",
    "                cypher_statement = f\"\"\"MERGE (e:entity {{entity_name: {'\"' + rows['entity_name'] + '\"'}}})\n",
    "                                    ON CREATE SET e.entity_type = {'\"' + rows['entity_type'] + '\"'},\n",
    "                                    e.occupation = {'\"' + rows['occupation'] + '\"'},\n",
    "                                    e.employer = {'\"' + rows['employer'] + '\"'}\"\"\"\n",
    "                tx.run(cypher_statement)\n",
    "                commit_limit +=1\n",
    "                if commit_limit == 100:\n",
    "                    tx.commit()\n",
    "                    commit_limit = 0\n",
    "                    tx = session.begin_transaction()\n",
    "                \n",
    "        session.close()\n",
    "        return self\n",
    "\n",
    "    def write_committee_transactions(self):\n",
    "        with self.conn.driver.session() as session:\n",
    "            tx  = session.begin_transaction()\n",
    "            commit_limit = 0\n",
    "            for index, rows in tqdm(self.committee_transactions.iterrows(), total=len(self.committee_transactions), desc=\"Inserting committee transactions\"):\n",
    "                committee_id = '\"' + str(rows['CMTE_ID']) + '\"'\n",
    "                amount = rows['TRANSACTION_AMT']\n",
    "                date = '\"' + str(rows['TRANSACTION_DT']) + '\"'\n",
    "                transaction_type = '\"' + str(rows['TRANSACTION_TP']) + '\"'\n",
    "                report_type = '\"' + str(rows['RPT_TP']) + '\"'\n",
    "                entity_name = '\"' + str(rows['NAME']).replace('\"', '') + '\"'\n",
    "                transaction_id = '\"' + str(rows['TRAN_ID']) + '\"'\n",
    "                memo_text = '\"' + str(rows['MEMO_TEXT']).replace('\"', '') + '\"'\n",
    "\n",
    "                cypher_statement = f\"\"\"MATCH (c:committee {{committee_id: {committee_id}}})\n",
    "                                MATCH (e:entity {{entity_name: {entity_name}}})\n",
    "                                MERGE (c)-[t:DISBURSES_TO]->(e)\n",
    "                                SET t.amount = {amount},\n",
    "                                t.date = {date},\n",
    "                                t.transaction_type = {transaction_type},\n",
    "                                t.report_type = {report_type},\n",
    "                                t.transaction_id = {transaction_id}\n",
    "                                t.memo_text = {memo_text}\n",
    "                                \"\"\"\n",
    "                tx.run(cypher_statement)\n",
    "                commit_limit +=1\n",
    "                if commit_limit == 100:\n",
    "                    tx.commit()\n",
    "                    commit_limit = 0\n",
    "                    tx = session.begin_transaction()\n",
    "                \n",
    "        session.close()\n",
    "        return self\n",
    "    \n",
    "    def load_individual_contributions(self):\n",
    "        #This dataset is so enormous that it requires PySpark to effectively filter\n",
    "        individual_contributions = spark.read.csv('raw_data/itcont.txt', sep='|')\n",
    "        new_columns = [\n",
    "        'CMTE_ID',\n",
    "        'AMNDT_IND',\n",
    "        'RPT_TP',\n",
    "        'TRANSACTION_PGI',\n",
    "        'IMAGE_NUM',\n",
    "        'TRANSACTION_TP',\n",
    "        'ENTITY_TP',\n",
    "        'NAME',\n",
    "        'CITY',\n",
    "        'STATE',\n",
    "        'ZIP_CODE',\n",
    "        'EMPLOYER',\n",
    "        'OCCUPATION',\n",
    "        'TRANSACTION_DT',\n",
    "        'TRANSACTION_AMT',\n",
    "        'OTHER_ID',\n",
    "        'TRAN_ID',\n",
    "        'FILE_NUM',\n",
    "        'MEMO_CD',\n",
    "        'MEMO_TEXT',\n",
    "        'SUB_ID']\n",
    "\n",
    "        individual_contributions = individual_contributions.toDF(*new_columns)\n",
    "        filtered = individual_contributions.filter(individual_contributions['TRANSACTION_AMT'] >= self.minimum_transaction)\n",
    "        self.individual_contributions = filtered.toPandas()\n",
    "        return self\n",
    "\n",
    "    def write_contributors(self):\n",
    "        with self.conn.driver.session() as session:\n",
    "            tx  = session.begin_transaction()\n",
    "            commit_limit = 0\n",
    "            for index, rows in tqdm(self.individual_contributions.iterrows(), total = len(self.individual_contributions), desc='Inserting individual Donors'):\n",
    "                entity_name = '\"' + str(rows['NAME']).replace('\"', '') + '\"'\n",
    "                entity_type = '\"' + str(rows['ENTITY_TP']) + '\"'\n",
    "                if rows['ENTITY_TP'] == 'IND':\n",
    "                    if rows['OCCUPATION'] is not None:\n",
    "                        occupation = str(rows['OCCUPATION']).replace('\"', '')\n",
    "                    else:\n",
    "                        occupation = 'None Listed'\n",
    "\n",
    "                    if rows['EMPLOYER'] is not None:\n",
    "                        employer = str(rows['EMPLOYER']).replace('\"', '')\n",
    "                    else:\n",
    "                        employer = 'None Listed'\n",
    "                else:\n",
    "                    occupation = 'N/A'\n",
    "                    employer = 'N/A'\n",
    "\n",
    "                cypher_statement = f\"\"\"MERGE (e:entity {{entity_name: {entity_name}}})\n",
    "                                    ON CREATE SET e.entity_type = {entity_type},\n",
    "                                    e.occupation = {'\"' + occupation + '\"'},\n",
    "                                    e.employer = {'\"' + employer + '\"'}\"\"\"\n",
    "                tx.run(cypher_statement)\n",
    "                commit_limit +=1\n",
    "                if commit_limit == 100:\n",
    "                    tx.commit()\n",
    "                    commit_limit = 0\n",
    "                    tx = session.begin_transaction()\n",
    "        session.close()\n",
    "        return self\n",
    "    \n",
    "    def write_CONTRIBUTES_TO(self):\n",
    "        with self.conn.driver.session() as session:\n",
    "            tx  = session.begin_transaction()\n",
    "            commit_limit = 0\n",
    "            for index, rows in tqdm(self.individual_contributions.iterrows(), total = len(self.individual_contributions), desc='Inserting donations'):\n",
    "                entity_name = '\"' + str(rows['NAME']).replace('\"', '') + '\"'\n",
    "                committee_id = '\"' + str(rows['CMTE_ID']).replace('\"', '') + '\"'\n",
    "                transaction_type = '\"' + str(rows['TRANSACTION_TP']) + '\"'\n",
    "                date = int(str(rows['TRANSACTION_DT']).replace('\"', ''))\n",
    "                amount = rows['TRANSACTION_AMT']\n",
    "                transaction_id = '\"' + str(rows['TRAN_ID']) + '\"'\n",
    "                \n",
    "                cypher_statement = f\"\"\"MATCH (e:entity {{entity_name: {entity_name}}})\n",
    "                                    MATCH (c:committee {{committee_id: {committee_id}}})\n",
    "                                    MERGE (e)-[r:CONTRIBUTES_TO]->(c)\n",
    "                                    SET r.transaction_type = {transaction_type},\n",
    "                                    r.date = {date},\n",
    "                                    r.amount = {amount},\n",
    "                                    r.transaction_id = {transaction_id}\"\"\"\n",
    "                tx.run(cypher_statement)\n",
    "                commit_limit +=1\n",
    "                if commit_limit == 100:\n",
    "                    tx.commit()\n",
    "                    commit_limit = 0\n",
    "                    tx = session.begin_transaction()\n",
    "        session.close()\n",
    "        return self\n",
    "    \n",
    "    def run_inserts(self):\n",
    "        self.load_candidates()\n",
    "        self.write_candidates()\n",
    "        self.load_committees()\n",
    "        self.write_committees()\n",
    "        self.write_affiliated_organizations()\n",
    "        self.write_AFFILIATED_WITH()\n",
    "        self.write_PRINCIPAL_COMMITTEE_OF()\n",
    "        self.load_committee_contributions()\n",
    "        self.write_COMMITTEE_CONTRIBUTES_TO()\n",
    "        self.write_LINKED_TO()\n",
    "        self.load_committee_transactions()\n",
    "        self.write_committee_transactions()\n",
    "        self.load_individual_contributions()\n",
    "        self.load_CONTRIBUTES_TO()\n",
    "        \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Neo4j\n"
     ]
    }
   ],
   "source": [
    "conn = Neo4jConnection()\n",
    "conn.uri = 'bolt://myneo4j:7687'\n",
    "conn.password = 'password'\n",
    "conn.connect_to_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d246fcd61e814499ad196db106f45fbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inserting committee contributions:   0%|          | 0/64511 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to read from defunct connection IPv4Address(('7668c613.databases.neo4j.io', 7687)) (ResolvedIPv4Address(('34.121.155.65', 7687)))\n"
     ]
    },
    {
     "ename": "SessionExpired",
     "evalue": "Failed to read from defunct connection IPv4Address(('7668c613.databases.neo4j.io', 7687)) (ResolvedIPv4Address(('34.121.155.65', 7687)))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/neo4j/_sync/io/_common.py:53\u001b[0m, in \u001b[0;36mInbox._buffer_one_chunk\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m chunk_size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;66;03m# Determine the chunk size and skip noop\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m     \u001b[43mreceive_into_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_socket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m     chunk_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer\u001b[38;5;241m.\u001b[39mpop_u16()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/neo4j/_sync/io/_common.py:308\u001b[0m, in \u001b[0;36mreceive_into_buffer\u001b[0;34m(sock, buffer, n_bytes)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m buffer\u001b[38;5;241m.\u001b[39mused \u001b[38;5;241m<\u001b[39m end:\n\u001b[0;32m--> 308\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mview\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbuffer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mused\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mused\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/neo4j/_async_compat/network/_bolt_socket.py:488\u001b[0m, in \u001b[0;36mBoltSocket.recv_into\u001b[0;34m(self, buffer, nbytes)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecv_into\u001b[39m(\u001b[38;5;28mself\u001b[39m, buffer, nbytes):\n\u001b[0;32m--> 488\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_io\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_socket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/neo4j/_async_compat/network/_bolt_socket.py:463\u001b[0m, in \u001b[0;36mBoltSocket._wait_for_io\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deadline \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    464\u001b[0m timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_socket\u001b[38;5;241m.\u001b[39mgettimeout()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1271\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1272\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1273\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mTimeoutError\u001b[0m: The read operation timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSessionExpired\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m parser \u001b[38;5;241m=\u001b[39m FECParser()\n\u001b[1;32m      2\u001b[0m parser\u001b[38;5;241m.\u001b[39mconn \u001b[38;5;241m=\u001b[39m conn\n\u001b[0;32m----> 3\u001b[0m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_inserts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[51], line 622\u001b[0m, in \u001b[0;36mFECParser.run_inserts\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_inserts\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;66;03m#self.load_candidates()\u001b[39;00m\n\u001b[1;32m    615\u001b[0m     \u001b[38;5;66;03m#self.write_candidates()\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;66;03m#self.write_AFFILIATED_WITH()\u001b[39;00m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;66;03m#self.write_PRINCIPAL_COMMITTEE_OF()\u001b[39;00m\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_committee_contributions()\n\u001b[0;32m--> 622\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_COMMITTEE_CONTRIBUTES_TO\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_LINKED_TO()\n\u001b[1;32m    624\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_committee_transactions()\n",
      "Cell \u001b[0;32mIn[51], line 373\u001b[0m, in \u001b[0;36mFECParser.write_COMMITTEE_CONTRIBUTES_TO\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    364\u001b[0m transaction_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(rows[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTRANSACTION_TP\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    366\u001b[0m cypher_statement \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mMATCH (c1:committee \u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;124mcommittee_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource_committee_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;124m            MATCH (c2:committee \u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;124mcommittee_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_committee_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;124m            MERGE (c1)-[t:CONTRIBUTES_TO]->(c2)\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;124m            t.amount = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mamount\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124m            t.transaction_type = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtransaction_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m--> 373\u001b[0m \u001b[43mtx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcypher_statement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m commit_limit \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m commit_limit \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m100\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/neo4j/_sync/work/transaction.py:161\u001b[0m, in \u001b[0;36mTransactionBase.run\u001b[0;34m(self, query, parameters, **kwparameters)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_results\u001b[38;5;241m.\u001b[39mappend(result)\n\u001b[1;32m    160\u001b[0m parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(parameters \u001b[38;5;129;01mor\u001b[39;00m {}, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwparameters)\n\u001b[0;32m--> 161\u001b[0m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tx_ready_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/neo4j/_sync/work/result.py:116\u001b[0m, in \u001b[0;36mResult._tx_ready_run\u001b[0;34m(self, query, parameters)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_tx_ready_run\u001b[39m(\u001b[38;5;28mself\u001b[39m, query, parameters):\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m# BEGIN+RUN does not carry any extra on the RUN message.\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;66;03m# BEGIN {extra}\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# RUN \"query\" {parameters} {extra}\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/neo4j/_sync/work/result.py:166\u001b[0m, in \u001b[0;36mResult._run\u001b[0;34m(self, query, parameters, db, imp_user, access_mode, bookmarks, notifications_min_severity, notifications_disabled_categories)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pull()\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39msend_all()\n\u001b[0;32m--> 166\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/neo4j/_sync/work/result.py:274\u001b[0m, in \u001b[0;36mResult._attach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exhausted \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attached \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/neo4j/_sync/io/_common.py:180\u001b[0m, in \u001b[0;36mConnectionErrorHandler.__getattr__.<locals>.outer.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 180\u001b[0m         \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (Neo4jError, ServiceUnavailable, SessionExpired) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    182\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39miscoroutinefunction(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__on_error)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/neo4j/_sync/io/_bolt.py:823\u001b[0m, in \u001b[0;36mBolt.fetch_message\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# Receive exactly one message\u001b[39;00m\n\u001b[0;32m--> 823\u001b[0m tag, fields \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minbox\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhydration_hooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponses\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhydration_hooks\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    826\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_message(tag, fields)\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midle_since \u001b[38;5;241m=\u001b[39m perf_counter()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/neo4j/_sync/io/_common.py:74\u001b[0m, in \u001b[0;36mInbox.pop\u001b[0;34m(self, hydration_hooks)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpop\u001b[39m(\u001b[38;5;28mself\u001b[39m, hydration_hooks):\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffer_one_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         size, tag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unpacker\u001b[38;5;241m.\u001b[39munpack_structure_header()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/neo4j/_sync/io/_common.py:70\u001b[0m, in \u001b[0;36mInbox._buffer_one_chunk\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;167;01mOSError\u001b[39;00m, SocketDeadlineExceeded, asyncio\u001b[38;5;241m.\u001b[39mCancelledError\n\u001b[1;32m     68\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_broken \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[43mUtil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/neo4j/_async_compat/util.py:111\u001b[0m, in \u001b[0;36mUtil.callback\u001b[0;34m(cb, *args, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcallback\u001b[39m(cb, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callable(cb):\n\u001b[0;32m--> 111\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcb\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/neo4j/_sync/io/_bolt.py:849\u001b[0m, in \u001b[0;36mBolt._set_defunct_read\u001b[0;34m(self, error, silent)\u001b[0m\n\u001b[1;32m    845\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_defunct_read\u001b[39m(\u001b[38;5;28mself\u001b[39m, error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    846\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to read from defunct connection \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    847\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munresolved_address, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserver_info\u001b[38;5;241m.\u001b[39maddress\n\u001b[1;32m    848\u001b[0m     )\n\u001b[0;32m--> 849\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_defunct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/neo4j/_sync/io/_bolt.py:901\u001b[0m, in \u001b[0;36mBolt._set_defunct\u001b[0;34m(self, message, error, silent)\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    900\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m error:\n\u001b[0;32m--> 901\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SessionExpired(message) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merror\u001b[39;00m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    903\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SessionExpired(message)\n",
      "\u001b[0;31mSessionExpired\u001b[0m: Failed to read from defunct connection IPv4Address(('7668c613.databases.neo4j.io', 7687)) (ResolvedIPv4Address(('34.121.155.65', 7687)))"
     ]
    }
   ],
   "source": [
    "parser = FECParser()\n",
    "parser.conn = conn\n",
    "parser.run_inserts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
